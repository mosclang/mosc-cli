// Generated automatically from src/packages/repl.msc. Do not edit.
static const char* replModuleSource =
"kabo \"fan\" nani Fan\n"
"kabo \"io\" nani Stdin, Stdout\n"
"kabo \"os\" nani Platform\n"
"\n"
"## Abstract base class for the REPL. Manages the input line and history, but\n"
"## does not render.\n"
"kulu Repl {\n"
"  nin _cursor;\n"
"  nin _line;\n"
"  nin _history;\n"
"  nin _historyIndex;\n"
"  dilan kura() {\n"
"    ale._cursor = 0\n"
"    ale._line = \"\"\n"
"\n"
"    ale._history = []\n"
"    ale._historyIndex = 0\n"
"  }\n"
"\n"
"  dialen start() {\n"
"     # convenience\n"
"     Fan.eval(\"kabo \\\"runtime\\\" nani Runtime\")\n"
"\n"
"    # Fire up the REPL. We use ANSI when talking to a POSIX TTY.\n"
"    nii (Platform.isPosix && Stdin.isTerminal) {\n"
"      AnsiRepl.kura().run()\n"
"    } note {\n"
"      # ANSI escape sequences probably aren't supported, so degrade.\n"
"      SimpleRepl.kura().run()\n"
"    }\n"
"\n"
"  }\n"
"  cursor { ale._cursor }\n"
"  cursor=(value) { ale._cursor = value }\n"
"  line { ale._line }\n"
"  line=(value) { ale._line = value }\n"
"\n"
"  run() {\n"
"    Stdin.isRaw = tien\n"
"    ale.refreshLine(galon)\n"
"\n"
"    foo (tien) {\n"
"      nin byte = Stdin.readByte()\n"
"      nii ale.handleChar(byte) atike\n"
"      ale.refreshLine(tien)\n"
"    }\n"
"  }\n"
"\n"
"  handleChar(byte) {\n"
"    nii (byte == Chars.ctrlC) {\n"
"      A.yira()\n"
"      segin niin tien\n"
"    } note nii (byte == Chars.ctrlD) {\n"
"      # If the line is empty, Ctrl_D exits.\n"
"      nii (ale._line.laKolon) {\n"
"        A.yira()\n"
"        segin niin tien\n"
"      }\n"
"\n"
"      # Otherwise, it deletes the character after the cursor.\n"
"      ale.deleteRight()\n"
"    } note nii (byte == Chars.tab) {\n"
"      nin completion = ale.getCompletion()\n"
"      nii (completion != gansan) {\n"
"        ale._line = ale._line + completion\n"
"        ale._cursor = ale._line.hakan\n"
"      }\n"
"    } note nii (byte == Chars.ctrlU) {\n"
"      # Clear the line.\n"
"      ale._line = \"\"\n"
"      ale._cursor = 0\n"
"    } note nii (byte == Chars.ctrlN) {\n"
"      ale.nextHistory()\n"
"    } note nii (byte == Chars.ctrlP) {\n"
"      ale.previousHistory()\n"
"    } note nii (byte == Chars.escape) {\n"
"      nin escapeType = Stdin.readByte()\n"
"      nin value = Stdin.readByte()\n"
"      nii (escapeType == Chars.leftBracket) {\n"
"        # ESC [ sequence.\n"
"        ale.handleEscapeBracket(value)\n"
"      } note {\n"
"        # TODO: Handle ESC 0 sequences.\n"
"      }\n"
"    } note nii (byte == Chars.carriageReturn) {\n"
"      ale.executeInput()\n"
"    } note nii (byte == Chars.delete) {\n"
"      ale.deleteLeft()\n"
"    } note nii (byte >= Chars.space && byte <= Chars.tilde) {\n"
"      ale.insertChar(byte)\n"
"    } note nii (byte == Chars.ctrlW) { # Handle Ctrl+w\n"
"      # Delete trailing spaces\n"
"      foo (ale._cursor != 0 && ale._line[ale._cursor - 1] == \" \") {\n"
"        ale.deleteLeft()\n"
"      }\n"
"      # Delete until the next space\n"
"      foo (ale._cursor != 0 && ale._line[ale._cursor - 1] != \" \") {\n"
"        ale.deleteLeft()\n"
"      }\n"
"    } note {\n"
"      # TODO: Other shortcuts?\n"
"      A.yira(\"Unhandled key-code [dec]: $byte\")\n"
"    }\n"
"\n"
"    segin niin galon\n"
"  }\n"
"\n"
"  ## Inserts the character with [byte] value at the current cursor position.\n"
"  insertChar(byte) {\n"
"    nin char = Seben.kaboCodePointna(byte)\n"
"    ale._line = ale._line[0...ale._cursor] + char + ale._line[ale._cursor..-1]\n"
"    ale._cursor = ale._cursor + 1\n"
"  }\n"
"\n"
"  ## Deletes the character before the cursor, if any.\n"
"  deleteLeft() {\n"
"    nii (ale._cursor == 0) segin\n"
"\n"
"    # Delete the character before the cursor.\n"
"    ale._line = ale._line[0...(ale._cursor - 1)] + ale._line[ale._cursor..-1]\n"
"    ale._cursor = ale._cursor - 1\n"
"  }\n"
"\n"
"  ## Deletes the character after the cursor, if any.\n"
"  deleteRight() {\n"
"    nii (ale._cursor == ale._line.hakan) segin\n"
"\n"
"    # Delete the character after the cursor.\n"
"    ale._line = ale._line[0...ale._cursor] + ale._line[(ale._cursor + 1)..-1]\n"
"  }\n"
"\n"
"  handleEscapeBracket(byte) {\n"
"    nii (byte == EscapeBracket.up) {\n"
"      ale.previousHistory()\n"
"    } note nii (byte == EscapeBracket.down) {\n"
"      ale.nextHistory()\n"
"    } note nii (byte == EscapeBracket.delete) {\n"
"      ale.deleteRight()\n"
"      # Consume extra 126 character generated by delete\n"
"      Stdin.readByte()\n"
"    } note nii (byte == EscapeBracket.end) {\n"
"      ale._cursor = ale._line.hakan\n"
"    } note nii (byte == EscapeBracket.home) {\n"
"      ale._cursor = 0\n"
"    }\n"
"  }\n"
"\n"
"  previousHistory() {\n"
"    nii ale._historyIndex == 0 segin\n"
"\n"
"    ale._historyIndex = ale._historyIndex - 1\n"
"    ale._line = ale._history[ale._historyIndex]\n"
"    ale._cursor = ale._line.hakan\n"
"  }\n"
"\n"
"  nextHistory() {\n"
"    nii (ale._historyIndex >= ale._history.hakan) segin\n"
"\n"
"    ale._historyIndex = ale._historyIndex + 1\n"
"    nii (ale._historyIndex < ale._history.hakan) {\n"
"      ale._line = ale._history[ale._historyIndex]\n"
"      ale._cursor = ale._line.hakan\n"
"    } note {\n"
"      ale._line = \"\"\n"
"      ale._cursor = 0\n"
"    }\n"
"  }\n"
"\n"
"  executeInput() {\n"
"    # Remove the completion hint.\n"
"    ale.refreshLine(galon)\n"
"\n"
"    # Add it to the history (if the line is interesting).\n"
"    nii (ale._line != \"\" && (ale._history.laKolon || ale._history[-1] != ale._line)) {\n"
"      ale._history.aFaraAkan(ale._line)\n"
"      ale._historyIndex = ale._history.hakan\n"
"    }\n"
"\n"
"    # Reset the current line.\n"
"    nin input = ale._line\n"
"    ale._line = \"\"\n"
"    ale._cursor = 0\n"
"\n"
"    A.yira()\n"
"\n"
"    # Guess if it looks like a statement or expression. If it looks like an\n"
"    # expression, we try to print the result.\n"
"    nin token = ale.lexFirst(input)\n"
"\n"
"    # No code, so do nothing.\n"
"    nii (token == gansan) segin\n"
"\n"
"    nin isStatement =\n"
"        token.type == Token.breakKeyword ||\n"
"        token.type == Token.classKeyword ||\n"
"        token.type == Token.forKeyword ||\n"
"        token.type == Token.externKeyword ||\n"
"        token.type == Token.ifKeyword ||\n"
"        token.type == Token.functionKeyword ||\n"
"        token.type == Token.continueKeyword ||\n"
"        token.type == Token.fromKeyword ||\n"
"        token.type == Token.importKeyword ||\n"
"        token.type == Token.returnKeyword ||\n"
"        token.type == Token.varKeyword ||\n"
"        token.type == Token.whileKeyword\n"
"\n"
"    nin closure = nii (isStatement) {\n"
"       # A.yira(\"Statement $input\")\n"
"       Fan.compile(input)\n"
"    } note {\n"
"      # A.yira(\"Expr:: $input\")\n"
"      Fan.compileExpression(input)\n"
"    }\n"
"    # A.yira(closure)\n"
"\n"
"    # Stop if there was a compile error.\n"
"    nii closure == gansan segin\n"
"\n"
"    nin fiber = Djuru.kura(closure)\n"
"\n"
"    nin result = fiber.aladie()\n"
"    nii (fiber.fili != gansan) {\n"
"      # TODO: Include callstack.\n"
"      ale.showRuntimeError(\"Runtime error: ${fiber.fili}\")\n"
"      segin\n"
"    }\n"
"\n"
"    nii (!isStatement) {\n"
"      ale.showResult(result)\n"
"    }\n"
"  }\n"
"\n"
"  lex(line, includeWhitespace) {\n"
"    nin lexer = Lexer.kura(line)\n"
"    nin tokens = []\n"
"    foo (tien) {\n"
"      nin token = lexer.readToken()\n"
"      nii (token.type == Token.eof) atike\n"
"\n"
"      nii (includeWhitespace ||\n"
"          (token.type != Token.comment && token.type != Token.whitespace)) {\n"
"        tokens.aFaraAkan(token)\n"
"      }\n"
"    }\n"
"\n"
"    segin niin tokens\n"
"  }\n"
"\n"
"  lexFirst(line) {\n"
"    nin lexer = Lexer.kura(line)\n"
"    foo tien {\n"
"      nin token = lexer.readToken()\n"
"      nii token.type == Token.eof segin niin gansan\n"
"\n"
"      nii (token.type != Token.comment && token.type != Token.whitespace) {\n"
"        segin niin token\n"
"      }\n"
"    }\n"
"  }\n"
"\n"
"  ## Gets the best possible auto-completion for the current line, or null if\n"
"  ## there is none. The completion is the remaining string to append to the\n"
"  ## line, not the entire completed line.\n"
"  getCompletion() {\n"
"    nii ale._line.laKolon segin niin gansan\n"
"\n"
"    # Only complete if the cursor is at the end.\n"
"    nii ale._cursor != ale._line.hakan segin niin gansan\n"
"\n"
"    seginka (Fan.variables(\"repl\") kono name) {\n"
"      # TODO: Also allow completion if the line ends with an identifier but\n"
"      # has other stuff before it.\n"
"      nii (name.beDamineNiin(ale._line)) {\n"
"        segin niin name[ale._line.hakan..-1]\n"
"      }\n"
"    }\n"
"  }\n"
"}\n"
"\n"
"## A reduced functionality REPL that doesn't use ANSI escape sequences.\n"
"kulu SimpleRepl ye Repl {\n"
"  nin _erase;\n"
"  dilan kura() {\n"
"    faa()\n"
"    ale._erase = \"\"\n"
"  }\n"
"\n"
"  refreshLine(showCompletion) {\n"
"    # A carriage return just moves the cursor to the beginning of the line.\n"
"    # We have to erase it manually. Since we can't use ANSI escapes, and we\n"
"    # don't know how wide the terminal is, erase the longest line we've seen\n"
"    # so far.\n"
"    nii ale.line.hakan > ale._erase.hakan ale._erase = \" \" * ale.line.hakan\n"
"    A.seben(\"\\r  ${ale._erase}\")\n"
"\n"
"    # Show the prompt at the beginning of the line.\n"
"    A.seben(\"\\r> \")\n"
"\n"
"    # Write the line.\n"
"    A.seben(ale.line)\n"
"    Stdout.flush()\n"
"  }\n"
"\n"
"  showResult(value) {\n"
"    # TODO: Syntax color based on type? It might be nice to distinguish\n"
"    # between string results versus stringified results. Otherwise, the\n"
"    # user can't tell the difference between `tien` and \"tien\".\n"
"    A.yira(value)\n"
"  }\n"
"\n"
"  showRuntimeError(message) {\n"
"    A.yira(message)\n"
"  }\n"
"}\n"
"\n"
"kulu AnsiRepl ye Repl {\n"
"  dilan kura() {\n"
"    faa()\n"
"  }\n"
"\n"
"  handleChar(byte) {\n"
"    nii (byte == Chars.ctrlA) {\n"
"      ale.cursor = 0\n"
"    } note nii (byte == Chars.ctrlB) {\n"
"      ale.cursorLeft()\n"
"    } note nii (byte == Chars.ctrlE) {\n"
"      ale.cursor = ale.line.hakan\n"
"    } note nii (byte == Chars.ctrlF) {\n"
"      ale.cursorRight()\n"
"    } note nii (byte == Chars.ctrlK){\n"
"      # Delete everything after the cursor.\n"
"      ale.line = ale.line[0...ale.cursor]\n"
"    } note nii (byte == Chars.ctrlL) {\n"
"      # Clear the screen.\n"
"      A.seben(\"\\x1b[2J\")\n"
"      # Move cursor to top left.\n"
"      A.seben(\"\\x1b[H\")\n"
"    } note {\n"
"      # TODO: Ctrl-T to swap chars.\n"
"      # TODO: ESC H and F to move to beginning and end of line. (Both ESC\n"
"      # [ and ESC 0 sequences?)\n"
"      # TODO: Ctrl-W delete previous word.\n"
"      segin niin faa.handleChar(byte)\n"
"    }\n"
"\n"
"    segin niin galon\n"
"  }\n"
"\n"
"  handleEscapeBracket(byte) {\n"
"    nii (byte == EscapeBracket.left) {\n"
"      ale.cursorLeft()\n"
"    } note nii (byte == EscapeBracket.right) {\n"
"      ale.cursorRight()\n"
"    }\n"
"\n"
"    faa.handleEscapeBracket(byte)\n"
"  }\n"
"\n"
"  ## Move the cursor left one character.\n"
"  cursorLeft() {\n"
"    nii ale.cursor > 0 ale.cursor = ale.cursor - 1\n"
"  }\n"
"\n"
"  ## Move the cursor right one character.\n"
"  cursorRight() {\n"
"    # TODO: Take into account multi-byte characters?\n"
"    nii ale.cursor < ale.line.hakan ale.cursor = ale.cursor + 1\n"
"  }\n"
"\n"
"  refreshLine(showCompletion) {\n"
"    # Erase the whole line.\n"
"    A.seben(\"\\x1b[2K\")\n"
"\n"
"    # Show the prompt at the beginning of the line.\n"
"    A.seben(Color.gray)\n"
"    A.seben(\"\\r> \")\n"
"    A.seben(Color.none)\n"
"\n"
"    # Syntax highlight the line.\n"
"    seginka (ale.lex(ale.line, tien) kono token) {\n"
"      nii token.type == Token.eof atike\n"
"      A.seben(TOKEN_COLORS[token.type])\n"
"      A.seben(token.text)\n"
"      A.seben(Color.none)\n"
"    }\n"
"\n"
"    nii (showCompletion) {\n"
"      nin completion = ale.getCompletion()\n"
"      nii (completion != gansan) {\n"
"        A.seben(\"${Color.gray}${completion}${Color.none}\")\n"
"      }\n"
"    }\n"
"\n"
"    # Position the cursor.\n"
"    A.seben(\"\\r\\x1b[${2 + ale.cursor}C\")\n"
"    Stdout.flush()\n"
"  }\n"
"\n"
"  showResult(value) {\n"
"    # TODO: Syntax color based on type? It might be nice to distinguish\n"
"    # between string results versus stringified results. Otherwise, the\n"
"    # user can't tell the difference between `tien` and \"tien\".\n"
"    A.yira(\"${Color.brightWhite}${value}${Color.none}\")\n"
"  }\n"
"\n"
"  showRuntimeError(message) {\n"
"    A.yira(\"${Color.red}${message}${Color.none}\")\n"
"    # TODO: Print entire stack.\n"
"  }\n"
"}\n"
"\n"
"## ANSI color escape sequences.\n"
"kulu Color {\n"
"  dialen none { \"\\x1b[0m\" }\n"
"  dialen black { \"\\x1b[30m\" }\n"
"  dialen red { \"\\x1b[31m\" }\n"
"  dialen green { \"\\x1b[32m\" }\n"
"  dialen yellow { \"\\x1b[33m\" }\n"
"  dialen blue { \"\\x1b[34m\" }\n"
"  dialen magenta { \"\\x1b[35m\" }\n"
"  dialen cyan { \"\\x1b[36m\" }\n"
"  dialen white { \"\\x1b[37m\" }\n"
"\n"
"  dialen gray { \"\\x1b[34;1m\" }\n"
"  dialen pink { \"\\x1b[31;1m\" }\n"
"  dialen brightWhite { \"\\x1b[37;1m\" }\n"
"}\n"
"\n"
"## Utilities for working with characters.\n"
"kulu Chars {\n"
"  dialen ctrlA { 0x01 }\n"
"  dialen ctrlB { 0x02 }\n"
"  dialen ctrlC { 0x03 }\n"
"  dialen ctrlD { 0x04 }\n"
"  dialen ctrlE { 0x05 }\n"
"  dialen ctrlF { 0x06 }\n"
"  dialen tab { 0x09 }\n"
"  dialen lineFeed { 0x0a }\n"
"  dialen ctrlK { 0x0b }\n"
"  dialen ctrlL { 0x0c }\n"
"  dialen carriageReturn { 0x0d }\n"
"  dialen ctrlN { 0x0e }\n"
"  dialen ctrlP { 0x10 }\n"
"  dialen ctrlU { 0x15 }\n"
"  dialen ctrlW { 0x17 }\n"
"  dialen escape { 0x1b }\n"
"  dialen space { 0x20 }\n"
"  dialen bang { 0x21 }\n"
"  dialen quote { 0x22 }\n"
"  dialen sharp { 0x23 }\n"
"  dialen dollar { 0x24 }\n"
"  dialen amp { 0x26 }\n"
"  dialen leftParen { 0x28 }\n"
"  dialen rightParen { 0x29 }\n"
"  dialen star { 0x2a }\n"
"  dialen plus { 0x2b }\n"
"  dialen comma { 0x2c }\n"
"  dialen minus { 0x2d }\n"
"  dialen dot { 0x2e }\n"
"  dialen slash { 0x2f }\n"
"\n"
"  dialen zero { 0x30 }\n"
"  dialen one { 0x31 }\n"
"  dialen two { 0x32 }\n"
"  dialen eight { 0x38 }\n"
"  dialen nine { 0x39 }\n"
"\n"
"  dialen colon { 0x3a }\n"
"  dialen less { 0x3c }\n"
"  dialen equal { 0x3d }\n"
"  dialen greater { 0x3e }\n"
"  dialen question { 0x3f }\n"
"\n"
"  dialen upperA { 0x41 }\n"
"  dialen upperB { 0x42 }\n"
"  dialen upperF { 0x46 }\n"
"  dialen upperO { 0x4f }\n"
"  dialen upperX { 0x58 }\n"
"  dialen upperZ { 0x5a }\n"
"\n"
"  dialen leftBracket { 0x5b }\n"
"  dialen backslash { 0x5c }\n"
"  dialen rightBracket { 0x5d }\n"
"  dialen caret { 0x5e }\n"
"  dialen underscore { 0x5f }\n"
"\n"
"  dialen lowerA { 0x61 }\n"
"  dialen lowerB { 0x62 }\n"
"  dialen lowerF { 0x66 }\n"
"  dialen lowerO { 0x6f }\n"
"  dialen lowerX { 0x78 }\n"
"  dialen lowerZ { 0x7a }\n"
"\n"
"  dialen leftBrace { 0x7b }\n"
"  dialen pipe { 0x7c }\n"
"  dialen rightBrace { 0x7d }\n"
"  dialen tilde { 0x7e }\n"
"  dialen delete { 0x7f }\n"
"\n"
"  dialen isAlpha(c) {\n"
"    segin niin c >= Chars.lowerA && c <= Chars.lowerZ ||\n"
"           c >= Chars.upperA && c <= Chars.upperZ ||\n"
"           c == Chars.underscore\n"
"  }\n"
"\n"
"  dialen isDigit(c) { c >= Chars.zero && c <= Chars.nine }\n"
"\n"
"  dialen isAlphaNumeric(c) { Chars.isAlpha(c) || Chars.isDigit(c) }\n"
"\n"
"  dialen isHexDigit(c) {\n"
"    segin niin c >= Chars.zero && c <= Chars.nine ||\n"
"           c >= Chars.lowerA && c <= Chars.lowerF ||\n"
"           c >= Chars.upperA && c <= Chars.upperF\n"
"  }\n"
"  dialen isOctDigit(c) {\n"
"    segin niin c >= Chars.zero && c < Chars.eight\n"
"  }\n"
"\n"
"  dialen isLowerAlpha(c) { c >= Chars.lowerA && c <= Chars.lowerZ }\n"
"\n"
"  dialen isWhitespace(c) { c == Chars.space || c == Chars.tab || c == Chars.carriageReturn }\n"
"}\n"
"\n"
"kulu EscapeBracket {\n"
"  dialen delete { 0x33 }\n"
"  dialen up { 0x41 }\n"
"  dialen down { 0x42 }\n"
"  dialen right { 0x43 }\n"
"  dialen left { 0x44 }\n"
"  dialen end { 0x46 }\n"
"  dialen home { 0x48 }\n"
"}\n"
"\n"
"kulu Token {\n"
"  # Punctuators.\n"
"  dialen leftParen { \"leftParen\" }\n"
"  dialen rightParen { \"rightParen\" }\n"
"  dialen leftBracket { \"leftBracket\" }\n"
"  dialen rightBracket { \"rightBracket\" }\n"
"  dialen leftBrace { \"leftBrace\" }\n"
"  dialen rightBrace { \"rightBrace\" }\n"
"  dialen colon { \"colon\" }\n"
"  dialen dot { \"dot\" }\n"
"  dialen dotDot { \"dotDot\" }\n"
"  dialen dotDotDot { \"dotDotDot\" }\n"
"  dialen comma { \"comma\" }\n"
"  dialen star { \"star\" }\n"
"  dialen slash { \"slash\" }\n"
"  dialen dollar { \"dollar\" }\n"
"  dialen plus { \"plus\" }\n"
"  dialen minus { \"minus\" }\n"
"  dialen pipe { \"pipe\" }\n"
"  dialen pipePipe { \"pipePipe\" }\n"
"  dialen caret { \"caret\" }\n"
"  dialen amp { \"amp\" }\n"
"  dialen ampAmp { \"ampAmp\" }\n"
"  # dialen question { \"question\" }\n"
"  dialen bang { \"bang\" }\n"
"  dialen tilde { \"tilde\" }\n"
"  dialen equal { \"equal\" }\n"
"  dialen less { \"less\" }\n"
"  dialen lessEqual { \"lessEqual\" }\n"
"  dialen lessLess { \"lessLess\" }\n"
"  dialen greater { \"greater\" }\n"
"  dialen greaterEqual { \"greaterEqual\" }\n"
"  dialen greaterGreater { \"greaterGreater\" }\n"
"  dialen equalEqual { \"equalEqual\" }\n"
"  dialen bangEqual { \"bangEqual\" }\n"
"\n"
"  # Keywords.\n"
"  dialen breakKeyword { \"atike\" }\n"
"  dialen classKeyword { \"kulu\" }\n"
"  dialen constructKeyword { \"dilan\" }\n"
"  dialen elseKeyword { \"note\" }\n"
"  dialen falseKeyword { \"galon\" }\n"
"  dialen forKeyword { \"seginka\" }\n"
"  dialen externKeyword { \"dunan\" }\n"
"  dialen ifKeyword { \"nii\" }\n"
"  dialen functionKeyword { \"nii\" }\n"
"  dialen importKeyword { \"nani\" }\n"
"  dialen fromKeyword { \"kabo\" }\n"
"  dialen inKeyword { \"kono\" }\n"
"  dialen isKeyword { \"ye\" }\n"
"  dialen nullKeyword { \"gansan\" }\n"
"  dialen returnKeyword { \"segin\" }\n"
"  dialen withKeyword { \"niin\" }\n"
"  dialen staticKeyword { \"dialen\" }\n"
"  dialen superKeyword { \"faa\" }\n"
"  dialen thisKeyword { \"ale\" }\n"
"  dialen tienKeyword { \"tien\" }\n"
"  dialen varKeyword { \"nin\" }\n"
"  dialen whileKeyword { \"foo\" }\n"
"  dialen whenKeyword { \"tumamin\" }\n"
"  dialen continueKeyword { \"ipan\" }\n"
"  dialen asKeyword { \"inafo\" }\n"
"  dialen upKeyword { \"kay\" }\n"
"  dialen downKeyword { \"kaj\" }\n"
"\n"
"  dialen field { \"field\" }\n"
"  dialen name { \"name\" }\n"
"  dialen number { \"number\" }\n"
"  dialen string { \"string\" }\n"
"  dialen interpolation { \"interpolation\" }\n"
"  dialen comment { \"comment\" }\n"
"  dialen whitespace { \"whitespace\" }\n"
"  dialen line { \"line\" }\n"
"  dialen error { \"error\" }\n"
"  dialen eof { \"eof\" }\n"
"\n"
"  nin _source\n"
"  nin _type\n"
"  nin _start\n"
"  nin _length\n"
"  dilan kura(source, type, start, length) {\n"
"    ale._source = source\n"
"    ale._type = type\n"
"    ale._start = start\n"
"    ale._length = length\n"
"  }\n"
"\n"
"  type { ale._type }\n"
"  text { ale._source[ale._start...(ale._start + ale._length)] }\n"
"\n"
"  start { ale._start }\n"
"  length { ale._length }\n"
"\n"
"  sebenma { ale.text }\n"
"}\n"
"\n"
"nin KEYWORDS = {\n"
"  \"atike\": Token.breakKeyword,\n"
"  \"kulu\": Token.classKeyword,\n"
"  \"dilan\": Token.constructKeyword,\n"
"  \"note\": Token.elseKeyword,\n"
"  \"galon\": Token.falseKeyword,\n"
"  \"seginka\": Token.forKeyword,\n"
"  \"dunan\": Token.externKeyword,\n"
"  \"nii\": Token.ifKeyword,\n"
"  \"tii\": Token.functionKeyword,\n"
"  \"nani\": Token.importKeyword,\n"
"  \"kabo\": Token.fromKeyword,\n"
"  \"kono\": Token.inKeyword,\n"
"  \"ye\": Token.isKeyword,\n"
"  \"gansan\": Token.nullKeyword,\n"
"  \"segin\": Token.returnKeyword,\n"
"  \"niin\": Token.withKeyword,\n"
"  \"dialen\": Token.staticKeyword,\n"
"  \"faa\": Token.superKeyword,\n"
"  \"ale\": Token.thisKeyword,\n"
"  \"tien\": Token.tienKeyword,\n"
"  \"nin\": Token.varKeyword,\n"
"  \"foo\": Token.whileKeyword,\n"
"  \"tumamin\": Token.whenKeyword,\n"
"  \"ipan\": Token.continueKeyword,\n"
"  \"inafo\": Token.asKeyword,\n"
"  \"kay\": Token.upKeyword,\n"
"  \"kaj\": Token.downKeyword,\n"
"}\n"
"\n"
"nin TOKEN_COLORS = {\n"
"  [Token.leftParen]: Color.gray,\n"
"  [Token.rightParen]: Color.gray,\n"
"  [Token.leftBracket]: Color.gray,\n"
"  [Token.rightBracket]: Color.gray,\n"
"  [Token.leftBrace]: Color.gray,\n"
"  [Token.rightBrace]: Color.gray,\n"
"  [Token.colon]: Color.gray,\n"
"  [Token.dot]: Color.gray,\n"
"  [Token.dotDot]: Color.none,\n"
"  [Token.dotDotDot]: Color.none,\n"
"  [Token.comma]: Color.gray,\n"
"  [Token.star]: Color.none,\n"
"  [Token.slash]: Color.none,\n"
"  [Token.dollar]: Color.none,\n"
"  [Token.plus]: Color.none,\n"
"  [Token.minus]: Color.none,\n"
"  [Token.pipe]: Color.none,\n"
"  [Token.pipePipe]: Color.none,\n"
"  [Token.caret]: Color.none,\n"
"  [Token.amp]: Color.none,\n"
"  [Token.ampAmp]: Color.none,\n"
"  # [Token.question]: Color.none,\n"
"  [Token.bang]: Color.none,\n"
"  [Token.tilde]: Color.none,\n"
"  [Token.equal]: Color.none,\n"
"  [Token.less]: Color.none,\n"
"  [Token.lessEqual]: Color.none,\n"
"  [Token.lessLess]: Color.none,\n"
"  [Token.greater]: Color.none,\n"
"  [Token.greaterEqual]: Color.none,\n"
"  [Token.greaterGreater]: Color.none,\n"
"  [Token.equalEqual]: Color.none,\n"
"  [Token.bangEqual]: Color.none,\n"
"\n"
"  # Keywords.\n"
"  [Token.breakKeyword]: Color.cyan,\n"
"  [Token.classKeyword]: Color.cyan,\n"
"  [Token.constructKeyword]: Color.cyan,\n"
"  [Token.elseKeyword]: Color.cyan,\n"
"  [Token.falseKeyword]: Color.cyan,\n"
"  [Token.forKeyword]: Color.cyan,\n"
"  [Token.externKeyword]: Color.cyan,\n"
"  [Token.ifKeyword]: Color.cyan,\n"
"  [Token.functionKeyword]: Color.cyan,\n"
"  [Token.withKeyword]: Color.cyan,\n"
"  [Token.importKeyword]: Color.cyan,\n"
"  [Token.fromKeyword]: Color.cyan,\n"
"  [Token.inKeyword]: Color.cyan,\n"
"  [Token.isKeyword]: Color.cyan,\n"
"  [Token.nullKeyword]: Color.cyan,\n"
"  [Token.returnKeyword]: Color.cyan,\n"
"  [Token.staticKeyword]: Color.cyan,\n"
"  [Token.superKeyword]: Color.cyan,\n"
"  [Token.thisKeyword]: Color.cyan,\n"
"  [Token.tienKeyword]: Color.cyan,\n"
"  [Token.varKeyword]: Color.cyan,\n"
"  [Token.whileKeyword]: Color.cyan,\n"
"  [Token.whenKeyword]: Color.cyan,\n"
"  [Token.continueKeyword]: Color.cyan,\n"
"  [Token.asKeyword]: Color.cyan,\n"
"  [Token.upKeyword]: Color.cyan,\n"
"  [Token.downKeyword]: Color.cyan,\n"
"\n"
"  [Token.field]: Color.none,\n"
"  [Token.name]: Color.none,\n"
"  [Token.number]: Color.magenta,\n"
"  [Token.string]: Color.yellow,\n"
"  [Token.interpolation]: Color.yellow,\n"
"  [Token.comment]: Color.gray,\n"
"  [Token.whitespace]: Color.none,\n"
"  [Token.line]: Color.none,\n"
"  [Token.error]: Color.red,\n"
"  [Token.eof]: Color.none,\n"
"}\n"
"\n"
"# Data table for tokens that are tokenized using maximal munch.\n"
"#\n"
"# The key is the character that starts the token or tokens. After that is a\n"
"# list of token types and characters. As long as the next character is matched,\n"
"# the type will update to the type after that character.\n"
"nin PUNCTUATORS = {\n"
"  [Chars.leftParen]: [Token.leftParen],\n"
"  [Chars.rightParen]: [Token.rightParen],\n"
"  [Chars.leftBracket]: [Token.leftBracket],\n"
"  [Chars.rightBracket]: [Token.rightBracket],\n"
"  [Chars.leftBrace]: [Token.leftBrace],\n"
"  [Chars.rightBrace]: [Token.rightBrace],\n"
"  [Chars.colon]: [Token.colon],\n"
"  [Chars.comma]: [Token.comma],\n"
"  [Chars.star]: [Token.star],\n"
"  [Chars.dollar]: [Token.dollar],\n"
"  [Chars.plus]: [Token.plus],\n"
"  [Chars.minus]: [Token.minus],\n"
"  [Chars.tilde]: [Token.tilde],\n"
"  [Chars.caret]: [Token.caret],\n"
"  # [Chars.question]: [Token.question],\n"
"  [Chars.lineFeed]: [Token.line],\n"
"\n"
"  [Chars.pipe]: [Token.pipe, Chars.pipe, Token.pipePipe],\n"
"  [Chars.amp]: [Token.amp, Chars.amp, Token.ampAmp],\n"
"  [Chars.bang]: [Token.bang, Chars.equal, Token.bangEqual],\n"
"  [Chars.equal]: [Token.equal, Chars.equal, Token.equalEqual],\n"
"\n"
"  [Chars.dot]: [Token.dot, Chars.dot, Token.dotDot, Chars.dot, Token.dotDotDot]\n"
"}\n"
"\n"
"## Tokenizes a string of input. This lexer differs from most in that it\n"
"## silently ignores errors from incomplete input, like a string literal with\n"
"## no closing quote. That's because this is intended to be run on a line of\n"
"## input while the user is still typing it.\n"
"kulu Lexer {\n"
"  nin _source\n"
"  nin _bytes\n"
"  nin _start\n"
"  nin _current\n"
"  nin _interpolations\n"
"  dilan kura(source) {\n"
"    ale._source = source\n"
"    # Due to the magic of UTF-8, we can safely treat Mosc source as a series\n"
"    # of bytes, since the only code points that are meaningful to Wren fit in\n"
"    # ASCII. The only place where non-ASCII code points can occur is inside\n"
"    # string literals and comments and the lexer safely treats those as opaque\n"
"    # bytes.\n"
"    ale._bytes = source.bytes\n"
"\n"
"    ale._start = 0\n"
"    ale._current = 0\n"
"\n"
"    # The stack of ongoing interpolated strings. Each element in the list is\n"
"    # a single level of interpolation nesting. The value of the element is the\n"
"    # number of unbalanced \"(\" still remaining to be closed.\n"
"    ale._interpolations = []\n"
"  }\n"
"\n"
"  readToken() {\n"
"    nii ale._current >= ale._bytes.hakan segin niin ale.makeToken(Token.eof)\n"
"\n"
"    ale._start = ale._current\n"
"    nin c = ale._bytes[ale._current]\n"
"    ale.advance()\n"
"\n"
"    nii (!ale._interpolations.laKolon) {\n"
"      nii (c == Chars.leftBrace) {\n"
"        ale._interpolations[-1] = ale._interpolations[-1] + 1\n"
"      } note nii (c == Chars.rightBrace) {\n"
"        ale._interpolations[-1] = ale._interpolations[-1] - 1\n"
"\n"
"        # The last \"}\" in an interpolated expression ends the expression and\n"
"        # resumes the string.\n"
"        nii (ale._interpolations[-1] == 0) {\n"
"          # This is the final \"}\", so the interpolation expression has ended.\n"
"          # This \"}\" now begins the next section of the template string.\n"
"          ale._interpolations.aBoOyorola(-1)\n"
"          segin niin ale.readString()\n"
"        }\n"
"      }\n"
"    }\n"
"\n"
"    nii (PUNCTUATORS.bAkono(c)) {\n"
"      nin punctuator = PUNCTUATORS[c]\n"
"      nin type = punctuator[0]\n"
"      nin i = 1\n"
"      foo (i < punctuator.hakan) {\n"
"        nii !ale.match(punctuator[i]) atike\n"
"        type = punctuator[i + 1]\n"
"        i = i + 2\n"
"      }\n"
"\n"
"      segin niin ale.makeToken(type)\n"
"    }\n"
"\n"
"    # Handle \"<\", \"<<\", and \"<=\".\n"
"    nii (c == Chars.less) {\n"
"      nii ale.match(Chars.less) segin niin ale.makeToken(Token.lessLess)\n"
"      nii ale.match(Chars.equal) segin niin ale.makeToken(Token.lessEqual)\n"
"      segin niin ale.makeToken(Token.less)\n"
"    }\n"
"\n"
"    # Handle \">\", \">>\", and \">=\".\n"
"    nii (c == Chars.greater) {\n"
"      nii ale.match(Chars.greater) segin niin ale.makeToken(Token.greaterGreater)\n"
"      nii ale.match(Chars.equal) segin niin ale.makeToken(Token.greaterEqual)\n"
"      segin niin ale.makeToken(Token.greater)\n"
"    }\n"
"\n"
"    # Handle \"#\", \"#\", and \"#*\".\n"
"    nii (c == Chars.sharp) {\n"
"      nii ale.match(Chars.star) segin niin ale.readBlockComment()\n"
"      segin niin ale.readLineComment()\n"
"      # segin niin ale.makeToken(Token.slash)\n"
"    }\n"
"\n"
"    # nii c == Chars.underscore segin niin ale.readField()\n"
"    nii c == Chars.quote segin niin ale.readString()\n"
"\n"
"    nii (c == Chars.zero) {\n"
"        nii (ale.peek() == Chars.lowerB || ale.peek() == Chars.upperB) segin niin ale.readBinNumber()\n"
"        nii (ale.peek() == Chars.lowerX || ale.peek() == Chars.upperX) segin niin ale.readHexNumber()\n"
"        nii (ale.peek() == Chars.lowerO || ale.peek() == Chars.upperO) segin niin ale.readOctNumber()\n"
"    }\n"
"    nii Chars.isWhitespace(c) segin niin ale.readWhitespace()\n"
"    nii Chars.isDigit(c) segin niin ale.readNumber()\n"
"    nii c == Chars.underscore || Chars.isAlpha(c) segin niin ale.readName()\n"
"\n"
"    segin niin ale.makeToken(Token.error)\n"
"  }\n"
"\n"
"  # Reads a line comment until the end of the line is reached.\n"
"  readLineComment() {\n"
"    # A line comment stops at the newline since newlines are significant.\n"
"    foo (ale.peek() != Chars.lineFeed && !ale.isAtEnd) {\n"
"      ale.advance()\n"
"    }\n"
"\n"
"    segin niin ale.makeToken(Token.comment)\n"
"  }\n"
"\n"
"  readBlockComment() {\n"
"    # Block comments can nest.\n"
"    nin nesting = 1\n"
"    foo (nesting > 0) {\n"
"      # TODO: Report error.\n"
"      nii ale.isAtEnd atike\n"
"\n"
"      nii (ale.peek() == Chars.sharp && ale.peek(1) == Chars.star) {\n"
"        ale.advance()\n"
"        ale.dvance()\n"
"        nesting = nesting + 1\n"
"      } note nii (ale.peek() == Chars.star && ale.peek(1) == Chars.sharp) {\n"
"        ale.advance()\n"
"        ale.advance()\n"
"        nesting = nesting - 1\n"
"        nii nesting == 0 atike\n"
"      } note {\n"
"        ale.advance()\n"
"      }\n"
"    }\n"
"\n"
"    segin niin ale.makeToken(Token.comment)\n"
"  }\n"
"\n"
"  # Reads a static or instance field.\n"
"  readField() {\n"
"    nin type = Token.field\n"
"\n"
"    # Read the rest of the name.\n"
"    foo (ale.match {(c) => Chars.isAlphaNumeric(c) }) {}\n"
"\n"
"    segin niin ale.makeToken(type)\n"
"  }\n"
"\n"
"  # Reads a string literal.\n"
"  readString() {\n"
"    nin type = Token.string\n"
"\n"
"    foo (!ale.isAtEnd) {\n"
"      nin c = ale._bytes[ale._current]\n"
"      ale.advance()\n"
"\n"
"      nii (c == Chars.backslash) {\n"
"        # TODO: Process specific escapes and validate them.\n"
"        nii (!ale.isAtEnd) ale.advance()\n"
"      } note nii (c == Chars.dollar) {\n"
"        # Consume the '{'.\n"
"        nii !ale.isAtEnd ale.advance()\n"
"        # TODO: Handle missing '{'.\n"
"        ale._interpolations.aFaraAkan(1)\n"
"        type = Token.interpolation\n"
"        atike\n"
"      } note nii (c == Chars.quote) {\n"
"        atike\n"
"      }\n"
"    }\n"
"\n"
"    segin niin ale.makeToken(type)\n"
"  }\n"
"\n"
"  # Reads a hexa number literal.\n"
"  readHexNumber() {\n"
"    # Skip past the `x`.\n"
"    ale.advance()\n"
"\n"
"    # Read the rest of the number.\n"
"    foo (ale.match {(c) => Chars.isHexDigit(c) }) {}\n"
"    segin niin ale.makeToken(Token.number)\n"
"  }\n"
"  # Reads a octal number literal.\n"
"  readOctNumber() {\n"
"    # Skip past the `o`.\n"
"    ale.advance()\n"
"\n"
"    # Read the rest of the number.\n"
"    foo (ale.match {(c) => Chars.isOctDigit(c) }) {}\n"
"    segin niin ale.makeToken(Token.number)\n"
"  }\n"
"  # Reads a binary number literal.\n"
"  readBinNumber() {\n"
"    # Skip past the `b`.\n"
"    ale.advance()\n"
"\n"
"    # Read the rest of the number.\n"
"    foo (ale.match {(c) => c >= Chars.zero && c <= Chars.one }) {}\n"
"    segin niin ale.makeToken(Token.number)\n"
"  }\n"
"\n"
"  # Reads a series of whitespace characters.\n"
"  readWhitespace() {\n"
"    # Read the rest of the whitespace.\n"
"    foo (ale.match {(c) => Chars.isWhitespace(c) }) {}\n"
"\n"
"    segin niin ale.makeToken(Token.whitespace)\n"
"  }\n"
"\n"
"  # Reads a number literal.\n"
"  readNumber() {\n"
"    # Read the rest of the number.\n"
"    foo (ale.match {(c) => Chars.isDigit(c) }) {}\n"
"\n"
"    # TODO: Floating point, scientific.\n"
"    segin niin ale.makeToken(Token.number)\n"
"  }\n"
"\n"
"  # Reads an identifier or keyword token.\n"
"  readName() {\n"
"    # Read the rest of the name.\n"
"    foo (ale.match {(c) => Chars.isAlphaNumeric(c) }) {}\n"
"\n"
"    nin text = ale._source[ale._start...ale._current]\n"
"    nin type = Token.name\n"
"    nii (KEYWORDS.bAkono(text)) {\n"
"      type = KEYWORDS[text]\n"
"    }\n"
"\n"
"    segin niin Token.kura(ale._source, type, ale._start, ale._current - ale._start)\n"
"  }\n"
"\n"
"  # Returns `tien` if we have scanned all characters.\n"
"  isAtEnd { ale._current >= ale._bytes.hakan }\n"
"\n"
"  # Advances past the current character.\n"
"  advance() {\n"
"    ale._current = ale._current + 1\n"
"  }\n"
"\n"
"  # Returns the byte value of the current character.\n"
"  peek() { ale.peek(0) }\n"
"\n"
"  # Returns the byte value of the character [n] bytes past the current\n"
"  # character.\n"
"  peek(n) {\n"
"    nii (ale._current + n >= ale._bytes.hakan) segin niin -1\n"
"    segin niin ale._bytes[ale._current + n]\n"
"  }\n"
"\n"
"  # Consumes the current character if it matches [condition], which can be a\n"
"  # numeric code point value or a function that takes a code point and returns\n"
"  # `tien` if the code point matches.\n"
"  match(condition) {\n"
"    nii (ale.isAtEnd) segin niin galon\n"
"\n"
"    nin c = ale._bytes[ale._current]\n"
"    nii (condition ye Tii) {\n"
"      nii (!condition.weele(c)) segin niin galon\n"
"    } note nii (c != condition) {\n"
"      segin niin galon\n"
"    }\n"
"\n"
"    ale.advance()\n"
"    segin niin tien\n"
"  }\n"
"\n"
"  # Creates a token of [type] from the current character range.\n"
"  makeToken(type) { Token.kura(ale._source, type, ale._start, ale._current - ale._start) }\n"
"}\n"
"\n";

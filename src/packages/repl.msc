kabo "fan" nani Fan
kabo "io" nani Stdin, Stdout
kabo "os" nani Platform

## Abstract base class for the REPL. Manages the input line and history, but
## does not render.
kulu Repl {
  nin _cursor;
  nin _line;
  nin _history;
  nin _historyIndex;
  dilan kura() {
    ale._cursor = 0
    ale._line = ""

    ale._history = []
    ale._historyIndex = 0
  }

  dialen start() {
     # convenience
     Fan.eval("kabo \"runtime\" nani Runtime")

    # Fire up the REPL. We use ANSI when talking to a POSIX TTY.
    nii (Platform.isPosix && Stdin.isTerminal) {
      AnsiRepl.kura().run()
    } note {
      # ANSI escape sequences probably aren't supported, so degrade.
      SimpleRepl.kura().run()
    }

  }
  cursor { ale._cursor }
  cursor=(value) { ale._cursor = value }
  line { ale._line }
  line=(value) { ale._line = value }

  run() {
    Stdin.isRaw = tien
    ale.refreshLine(galon)

    foo (tien) {
      nin byte = Stdin.readByte()
      nii ale.handleChar(byte) atike
      ale.refreshLine(tien)
    }
  }

  handleChar(byte) {
    nii (byte == Chars.ctrlC) {
      A.yira()
      segin niin tien
    } note nii (byte == Chars.ctrlD) {
      # If the line is empty, Ctrl_D exits.
      nii (ale._line.laKolon) {
        A.yira()
        segin niin tien
      }

      # Otherwise, it deletes the character after the cursor.
      ale.deleteRight()
    } note nii (byte == Chars.tab) {
      nin completion = ale.getCompletion()
      nii (completion != gansan) {
        ale._line = ale._line + completion
        ale._cursor = ale._line.hakan
      }
    } note nii (byte == Chars.ctrlU) {
      # Clear the line.
      ale._line = ""
      ale._cursor = 0
    } note nii (byte == Chars.ctrlN) {
      ale.nextHistory()
    } note nii (byte == Chars.ctrlP) {
      ale.previousHistory()
    } note nii (byte == Chars.escape) {
      nin escapeType = Stdin.readByte()
      nin value = Stdin.readByte()
      nii (escapeType == Chars.leftBracket) {
        # ESC [ sequence.
        ale.handleEscapeBracket(value)
      } note {
        # TODO: Handle ESC 0 sequences.
      }
    } note nii (byte == Chars.carriageReturn) {
      ale.executeInput()
    } note nii (byte == Chars.delete) {
      ale.deleteLeft()
    } note nii (byte >= Chars.space && byte <= Chars.tilde) {
      ale.insertChar(byte)
    } note nii (byte == Chars.ctrlW) { # Handle Ctrl+w
      # Delete trailing spaces
      foo (ale._cursor != 0 && ale._line[ale._cursor - 1] == " ") {
        ale.deleteLeft()
      }
      # Delete until the next space
      foo (ale._cursor != 0 && ale._line[ale._cursor - 1] != " ") {
        ale.deleteLeft()
      }
    } note {
      # TODO: Other shortcuts?
      A.yira("Unhandled key-code [dec]: $byte")
    }

    segin niin galon
  }

  ## Inserts the character with [byte] value at the current cursor position.
  insertChar(byte) {
    nin char = Seben.kaboCodePointna(byte)
    ale._line = ale._line[0...ale._cursor] + char + ale._line[ale._cursor..-1]
    ale._cursor = ale._cursor + 1
  }

  ## Deletes the character before the cursor, if any.
  deleteLeft() {
    nii (ale._cursor == 0) segin

    # Delete the character before the cursor.
    ale._line = ale._line[0...(ale._cursor - 1)] + ale._line[ale._cursor..-1]
    ale._cursor = ale._cursor - 1
  }

  ## Deletes the character after the cursor, if any.
  deleteRight() {
    nii (ale._cursor == ale._line.hakan) segin

    # Delete the character after the cursor.
    ale._line = ale._line[0...ale._cursor] + ale._line[(ale._cursor + 1)..-1]
  }

  handleEscapeBracket(byte) {
    nii (byte == EscapeBracket.up) {
      ale.previousHistory()
    } note nii (byte == EscapeBracket.down) {
      ale.nextHistory()
    } note nii (byte == EscapeBracket.delete) {
      ale.deleteRight()
      # Consume extra 126 character generated by delete
      Stdin.readByte()
    } note nii (byte == EscapeBracket.end) {
      ale._cursor = ale._line.hakan
    } note nii (byte == EscapeBracket.home) {
      ale._cursor = 0
    }
  }

  previousHistory() {
    nii ale._historyIndex == 0 segin

    ale._historyIndex = ale._historyIndex - 1
    ale._line = ale._history[ale._historyIndex]
    ale._cursor = ale._line.hakan
  }

  nextHistory() {
    nii (ale._historyIndex >= ale._history.hakan) segin

    ale._historyIndex = ale._historyIndex + 1
    nii (ale._historyIndex < ale._history.hakan) {
      ale._line = ale._history[ale._historyIndex]
      ale._cursor = ale._line.hakan
    } note {
      ale._line = ""
      ale._cursor = 0
    }
  }

  executeInput() {
    # Remove the completion hint.
    ale.refreshLine(galon)

    # Add it to the history (if the line is interesting).
    nii (ale._line != "" && (ale._history.laKolon || ale._history[-1] != ale._line)) {
      ale._history.aFaraAkan(ale._line)
      ale._historyIndex = ale._history.hakan
    }

    # Reset the current line.
    nin input = ale._line
    ale._line = ""
    ale._cursor = 0

    A.yira()

    # Guess if it looks like a statement or expression. If it looks like an
    # expression, we try to print the result.
    nin token = ale.lexFirst(input)

    # No code, so do nothing.
    nii (token == gansan) segin

    nin isStatement =
        token.type == Token.breakKeyword ||
        token.type == Token.classKeyword ||
        token.type == Token.forKeyword ||
        token.type == Token.externKeyword ||
        token.type == Token.ifKeyword ||
        token.type == Token.functionKeyword ||
        token.type == Token.continueKeyword ||
        token.type == Token.fromKeyword ||
        token.type == Token.importKeyword ||
        token.type == Token.returnKeyword ||
        token.type == Token.varKeyword ||
        token.type == Token.whileKeyword

    nin closure = nii (isStatement) {
       # A.yira("Statement $input")
       Fan.compile(input)
    } note {
      # A.yira("Expr:: $input")
      Fan.compileExpression(input)
    }
    # A.yira(closure)

    # Stop if there was a compile error.
    nii closure == gansan segin

    nin fiber = Djuru.kura(closure)

    nin result = fiber.aladie()
    nii (fiber.fili != gansan) {
      # TODO: Include callstack.
      ale.showRuntimeError("Runtime error: ${fiber.fili}")
      segin
    }

    nii (!isStatement) {
      ale.showResult(result)
    }
  }

  lex(line, includeWhitespace) {
    nin lexer = Lexer.kura(line)
    nin tokens = []
    foo (tien) {
      nin token = lexer.readToken()
      nii (token.type == Token.eof) atike

      nii (includeWhitespace ||
          (token.type != Token.comment && token.type != Token.whitespace)) {
        tokens.aFaraAkan(token)
      }
    }

    segin niin tokens
  }

  lexFirst(line) {
    nin lexer = Lexer.kura(line)
    foo tien {
      nin token = lexer.readToken()
      nii token.type == Token.eof segin niin gansan

      nii (token.type != Token.comment && token.type != Token.whitespace) {
        segin niin token
      }
    }
  }

  ## Gets the best possible auto-completion for the current line, or null if
  ## there is none. The completion is the remaining string to append to the
  ## line, not the entire completed line.
  getCompletion() {
    nii ale._line.laKolon segin niin gansan

    # Only complete if the cursor is at the end.
    nii ale._cursor != ale._line.hakan segin niin gansan

    seginka (Fan.variables("repl") kono name) {
      # TODO: Also allow completion if the line ends with an identifier but
      # has other stuff before it.
      nii (name.beDamineNiin(ale._line)) {
        segin niin name[ale._line.hakan..-1]
      }
    }
  }
}

## A reduced functionality REPL that doesn't use ANSI escape sequences.
kulu SimpleRepl ye Repl {
  nin _erase;
  dilan kura() {
    faa()
    ale._erase = ""
  }

  refreshLine(showCompletion) {
    # A carriage return just moves the cursor to the beginning of the line.
    # We have to erase it manually. Since we can't use ANSI escapes, and we
    # don't know how wide the terminal is, erase the longest line we've seen
    # so far.
    nii ale.line.hakan > ale._erase.hakan ale._erase = " " * ale.line.hakan
    A.seben("\r  ${ale._erase}")

    # Show the prompt at the beginning of the line.
    A.seben("\r> ")

    # Write the line.
    A.seben(ale.line)
    Stdout.flush()
  }

  showResult(value) {
    # TODO: Syntax color based on type? It might be nice to distinguish
    # between string results versus stringified results. Otherwise, the
    # user can't tell the difference between `tien` and "tien".
    A.yira(value)
  }

  showRuntimeError(message) {
    A.yira(message)
  }
}

kulu AnsiRepl ye Repl {
  dilan kura() {
    faa()
  }

  handleChar(byte) {
    nii (byte == Chars.ctrlA) {
      ale.cursor = 0
    } note nii (byte == Chars.ctrlB) {
      ale.cursorLeft()
    } note nii (byte == Chars.ctrlE) {
      ale.cursor = ale.line.hakan
    } note nii (byte == Chars.ctrlF) {
      ale.cursorRight()
    } note nii (byte == Chars.ctrlK){
      # Delete everything after the cursor.
      ale.line = ale.line[0...ale.cursor]
    } note nii (byte == Chars.ctrlL) {
      # Clear the screen.
      A.seben("\x1b[2J")
      # Move cursor to top left.
      A.seben("\x1b[H")
    } note {
      # TODO: Ctrl-T to swap chars.
      # TODO: ESC H and F to move to beginning and end of line. (Both ESC
      # [ and ESC 0 sequences?)
      # TODO: Ctrl-W delete previous word.
      segin niin faa.handleChar(byte)
    }

    segin niin galon
  }

  handleEscapeBracket(byte) {
    nii (byte == EscapeBracket.left) {
      ale.cursorLeft()
    } note nii (byte == EscapeBracket.right) {
      ale.cursorRight()
    }

    faa.handleEscapeBracket(byte)
  }

  ## Move the cursor left one character.
  cursorLeft() {
    nii ale.cursor > 0 ale.cursor = ale.cursor - 1
  }

  ## Move the cursor right one character.
  cursorRight() {
    # TODO: Take into account multi-byte characters?
    nii ale.cursor < ale.line.hakan ale.cursor = ale.cursor + 1
  }

  refreshLine(showCompletion) {
    # Erase the whole line.
    A.seben("\x1b[2K")

    # Show the prompt at the beginning of the line.
    A.seben(Color.gray)
    A.seben("\r> ")
    A.seben(Color.none)

    # Syntax highlight the line.
    seginka (ale.lex(ale.line, tien) kono token) {
      nii token.type == Token.eof atike
      A.seben(TOKEN_COLORS[token.type])
      A.seben(token.text)
      A.seben(Color.none)
    }

    nii (showCompletion) {
      nin completion = ale.getCompletion()
      nii (completion != gansan) {
        A.seben("${Color.gray}${completion}${Color.none}")
      }
    }

    # Position the cursor.
    A.seben("\r\x1b[${2 + ale.cursor}C")
    Stdout.flush()
  }

  showResult(value) {
    # TODO: Syntax color based on type? It might be nice to distinguish
    # between string results versus stringified results. Otherwise, the
    # user can't tell the difference between `tien` and "tien".
    A.yira("${Color.brightWhite}${value}${Color.none}")
  }

  showRuntimeError(message) {
    A.yira("${Color.red}${message}${Color.none}")
    # TODO: Print entire stack.
  }
}

## ANSI color escape sequences.
kulu Color {
  dialen none { "\x1b[0m" }
  dialen black { "\x1b[30m" }
  dialen red { "\x1b[31m" }
  dialen green { "\x1b[32m" }
  dialen yellow { "\x1b[33m" }
  dialen blue { "\x1b[34m" }
  dialen magenta { "\x1b[35m" }
  dialen cyan { "\x1b[36m" }
  dialen white { "\x1b[37m" }

  dialen gray { "\x1b[34;1m" }
  dialen pink { "\x1b[31;1m" }
  dialen brightWhite { "\x1b[37;1m" }
}

## Utilities for working with characters.
kulu Chars {
  dialen ctrlA { 0x01 }
  dialen ctrlB { 0x02 }
  dialen ctrlC { 0x03 }
  dialen ctrlD { 0x04 }
  dialen ctrlE { 0x05 }
  dialen ctrlF { 0x06 }
  dialen tab { 0x09 }
  dialen lineFeed { 0x0a }
  dialen ctrlK { 0x0b }
  dialen ctrlL { 0x0c }
  dialen carriageReturn { 0x0d }
  dialen ctrlN { 0x0e }
  dialen ctrlP { 0x10 }
  dialen ctrlU { 0x15 }
  dialen ctrlW { 0x17 }
  dialen escape { 0x1b }
  dialen space { 0x20 }
  dialen bang { 0x21 }
  dialen quote { 0x22 }
  dialen sharp { 0x23 }
  dialen dollar { 0x24 }
  dialen amp { 0x26 }
  dialen leftParen { 0x28 }
  dialen rightParen { 0x29 }
  dialen star { 0x2a }
  dialen plus { 0x2b }
  dialen comma { 0x2c }
  dialen minus { 0x2d }
  dialen dot { 0x2e }
  dialen slash { 0x2f }

  dialen zero { 0x30 }
  dialen one { 0x31 }
  dialen two { 0x32 }
  dialen eight { 0x38 }
  dialen nine { 0x39 }

  dialen colon { 0x3a }
  dialen less { 0x3c }
  dialen equal { 0x3d }
  dialen greater { 0x3e }
  dialen question { 0x3f }

  dialen upperA { 0x41 }
  dialen upperB { 0x42 }
  dialen upperF { 0x46 }
  dialen upperO { 0x4f }
  dialen upperX { 0x58 }
  dialen upperZ { 0x5a }

  dialen leftBracket { 0x5b }
  dialen backslash { 0x5c }
  dialen rightBracket { 0x5d }
  dialen caret { 0x5e }
  dialen underscore { 0x5f }

  dialen lowerA { 0x61 }
  dialen lowerB { 0x62 }
  dialen lowerF { 0x66 }
  dialen lowerO { 0x6f }
  dialen lowerX { 0x78 }
  dialen lowerZ { 0x7a }

  dialen leftBrace { 0x7b }
  dialen pipe { 0x7c }
  dialen rightBrace { 0x7d }
  dialen tilde { 0x7e }
  dialen delete { 0x7f }

  dialen isAlpha(c) {
    segin niin c >= Chars.lowerA && c <= Chars.lowerZ ||
           c >= Chars.upperA && c <= Chars.upperZ ||
           c == Chars.underscore
  }

  dialen isDigit(c) { c >= Chars.zero && c <= Chars.nine }

  dialen isAlphaNumeric(c) { Chars.isAlpha(c) || Chars.isDigit(c) }

  dialen isHexDigit(c) {
    segin niin c >= Chars.zero && c <= Chars.nine ||
           c >= Chars.lowerA && c <= Chars.lowerF ||
           c >= Chars.upperA && c <= Chars.upperF
  }
  dialen isOctDigit(c) {
    segin niin c >= Chars.zero && c < Chars.eight
  }

  dialen isLowerAlpha(c) { c >= Chars.lowerA && c <= Chars.lowerZ }

  dialen isWhitespace(c) { c == Chars.space || c == Chars.tab || c == Chars.carriageReturn }
}

kulu EscapeBracket {
  dialen delete { 0x33 }
  dialen up { 0x41 }
  dialen down { 0x42 }
  dialen right { 0x43 }
  dialen left { 0x44 }
  dialen end { 0x46 }
  dialen home { 0x48 }
}

kulu Token {
  # Punctuators.
  dialen leftParen { "leftParen" }
  dialen rightParen { "rightParen" }
  dialen leftBracket { "leftBracket" }
  dialen rightBracket { "rightBracket" }
  dialen leftBrace { "leftBrace" }
  dialen rightBrace { "rightBrace" }
  dialen colon { "colon" }
  dialen dot { "dot" }
  dialen dotDot { "dotDot" }
  dialen dotDotDot { "dotDotDot" }
  dialen comma { "comma" }
  dialen star { "star" }
  dialen slash { "slash" }
  dialen dollar { "dollar" }
  dialen plus { "plus" }
  dialen minus { "minus" }
  dialen pipe { "pipe" }
  dialen pipePipe { "pipePipe" }
  dialen caret { "caret" }
  dialen amp { "amp" }
  dialen ampAmp { "ampAmp" }
  # dialen question { "question" }
  dialen bang { "bang" }
  dialen tilde { "tilde" }
  dialen equal { "equal" }
  dialen less { "less" }
  dialen lessEqual { "lessEqual" }
  dialen lessLess { "lessLess" }
  dialen greater { "greater" }
  dialen greaterEqual { "greaterEqual" }
  dialen greaterGreater { "greaterGreater" }
  dialen equalEqual { "equalEqual" }
  dialen bangEqual { "bangEqual" }

  # Keywords.
  dialen breakKeyword { "atike" }
  dialen classKeyword { "kulu" }
  dialen constructKeyword { "dilan" }
  dialen elseKeyword { "note" }
  dialen falseKeyword { "galon" }
  dialen forKeyword { "seginka" }
  dialen externKeyword { "dunan" }
  dialen ifKeyword { "nii" }
  dialen functionKeyword { "nii" }
  dialen importKeyword { "nani" }
  dialen fromKeyword { "kabo" }
  dialen inKeyword { "kono" }
  dialen isKeyword { "ye" }
  dialen nullKeyword { "gansan" }
  dialen returnKeyword { "segin" }
  dialen withKeyword { "niin" }
  dialen staticKeyword { "dialen" }
  dialen superKeyword { "faa" }
  dialen thisKeyword { "ale" }
  dialen tienKeyword { "tien" }
  dialen varKeyword { "nin" }
  dialen whileKeyword { "foo" }
  dialen whenKeyword { "tumamin" }
  dialen continueKeyword { "ipan" }
  dialen asKeyword { "inafo" }
  dialen upKeyword { "kay" }
  dialen downKeyword { "kaj" }

  dialen field { "field" }
  dialen name { "name" }
  dialen number { "number" }
  dialen string { "string" }
  dialen interpolation { "interpolation" }
  dialen comment { "comment" }
  dialen whitespace { "whitespace" }
  dialen line { "line" }
  dialen error { "error" }
  dialen eof { "eof" }

  nin _source
  nin _type
  nin _start
  nin _length
  dilan kura(source, type, start, length) {
    ale._source = source
    ale._type = type
    ale._start = start
    ale._length = length
  }

  type { ale._type }
  text { ale._source[ale._start...(ale._start + ale._length)] }

  start { ale._start }
  length { ale._length }

  sebenma { ale.text }
}

nin KEYWORDS = {
  "atike": Token.breakKeyword,
  "kulu": Token.classKeyword,
  "dilan": Token.constructKeyword,
  "note": Token.elseKeyword,
  "galon": Token.falseKeyword,
  "seginka": Token.forKeyword,
  "dunan": Token.externKeyword,
  "nii": Token.ifKeyword,
  "tii": Token.functionKeyword,
  "nani": Token.importKeyword,
  "kabo": Token.fromKeyword,
  "kono": Token.inKeyword,
  "ye": Token.isKeyword,
  "gansan": Token.nullKeyword,
  "segin": Token.returnKeyword,
  "niin": Token.withKeyword,
  "dialen": Token.staticKeyword,
  "faa": Token.superKeyword,
  "ale": Token.thisKeyword,
  "tien": Token.tienKeyword,
  "nin": Token.varKeyword,
  "foo": Token.whileKeyword,
  "tumamin": Token.whenKeyword,
  "ipan": Token.continueKeyword,
  "inafo": Token.asKeyword,
  "kay": Token.upKeyword,
  "kaj": Token.downKeyword,
}

nin TOKEN_COLORS = {
  [Token.leftParen]: Color.gray,
  [Token.rightParen]: Color.gray,
  [Token.leftBracket]: Color.gray,
  [Token.rightBracket]: Color.gray,
  [Token.leftBrace]: Color.gray,
  [Token.rightBrace]: Color.gray,
  [Token.colon]: Color.gray,
  [Token.dot]: Color.gray,
  [Token.dotDot]: Color.none,
  [Token.dotDotDot]: Color.none,
  [Token.comma]: Color.gray,
  [Token.star]: Color.none,
  [Token.slash]: Color.none,
  [Token.dollar]: Color.none,
  [Token.plus]: Color.none,
  [Token.minus]: Color.none,
  [Token.pipe]: Color.none,
  [Token.pipePipe]: Color.none,
  [Token.caret]: Color.none,
  [Token.amp]: Color.none,
  [Token.ampAmp]: Color.none,
  # [Token.question]: Color.none,
  [Token.bang]: Color.none,
  [Token.tilde]: Color.none,
  [Token.equal]: Color.none,
  [Token.less]: Color.none,
  [Token.lessEqual]: Color.none,
  [Token.lessLess]: Color.none,
  [Token.greater]: Color.none,
  [Token.greaterEqual]: Color.none,
  [Token.greaterGreater]: Color.none,
  [Token.equalEqual]: Color.none,
  [Token.bangEqual]: Color.none,

  # Keywords.
  [Token.breakKeyword]: Color.cyan,
  [Token.classKeyword]: Color.cyan,
  [Token.constructKeyword]: Color.cyan,
  [Token.elseKeyword]: Color.cyan,
  [Token.falseKeyword]: Color.cyan,
  [Token.forKeyword]: Color.cyan,
  [Token.externKeyword]: Color.cyan,
  [Token.ifKeyword]: Color.cyan,
  [Token.functionKeyword]: Color.cyan,
  [Token.withKeyword]: Color.cyan,
  [Token.importKeyword]: Color.cyan,
  [Token.fromKeyword]: Color.cyan,
  [Token.inKeyword]: Color.cyan,
  [Token.isKeyword]: Color.cyan,
  [Token.nullKeyword]: Color.cyan,
  [Token.returnKeyword]: Color.cyan,
  [Token.staticKeyword]: Color.cyan,
  [Token.superKeyword]: Color.cyan,
  [Token.thisKeyword]: Color.cyan,
  [Token.tienKeyword]: Color.cyan,
  [Token.varKeyword]: Color.cyan,
  [Token.whileKeyword]: Color.cyan,
  [Token.whenKeyword]: Color.cyan,
  [Token.continueKeyword]: Color.cyan,
  [Token.asKeyword]: Color.cyan,
  [Token.upKeyword]: Color.cyan,
  [Token.downKeyword]: Color.cyan,

  [Token.field]: Color.none,
  [Token.name]: Color.none,
  [Token.number]: Color.magenta,
  [Token.string]: Color.yellow,
  [Token.interpolation]: Color.yellow,
  [Token.comment]: Color.gray,
  [Token.whitespace]: Color.none,
  [Token.line]: Color.none,
  [Token.error]: Color.red,
  [Token.eof]: Color.none,
}

# Data table for tokens that are tokenized using maximal munch.
#
# The key is the character that starts the token or tokens. After that is a
# list of token types and characters. As long as the next character is matched,
# the type will update to the type after that character.
nin PUNCTUATORS = {
  [Chars.leftParen]: [Token.leftParen],
  [Chars.rightParen]: [Token.rightParen],
  [Chars.leftBracket]: [Token.leftBracket],
  [Chars.rightBracket]: [Token.rightBracket],
  [Chars.leftBrace]: [Token.leftBrace],
  [Chars.rightBrace]: [Token.rightBrace],
  [Chars.colon]: [Token.colon],
  [Chars.comma]: [Token.comma],
  [Chars.star]: [Token.star],
  [Chars.dollar]: [Token.dollar],
  [Chars.plus]: [Token.plus],
  [Chars.minus]: [Token.minus],
  [Chars.tilde]: [Token.tilde],
  [Chars.caret]: [Token.caret],
  # [Chars.question]: [Token.question],
  [Chars.lineFeed]: [Token.line],

  [Chars.pipe]: [Token.pipe, Chars.pipe, Token.pipePipe],
  [Chars.amp]: [Token.amp, Chars.amp, Token.ampAmp],
  [Chars.bang]: [Token.bang, Chars.equal, Token.bangEqual],
  [Chars.equal]: [Token.equal, Chars.equal, Token.equalEqual],

  [Chars.dot]: [Token.dot, Chars.dot, Token.dotDot, Chars.dot, Token.dotDotDot]
}

## Tokenizes a string of input. This lexer differs from most in that it
## silently ignores errors from incomplete input, like a string literal with
## no closing quote. That's because this is intended to be run on a line of
## input while the user is still typing it.
kulu Lexer {
  nin _source
  nin _bytes
  nin _start
  nin _current
  nin _interpolations
  dilan kura(source) {
    ale._source = source
    # Due to the magic of UTF-8, we can safely treat Mosc source as a series
    # of bytes, since the only code points that are meaningful to Wren fit in
    # ASCII. The only place where non-ASCII code points can occur is inside
    # string literals and comments and the lexer safely treats those as opaque
    # bytes.
    ale._bytes = source.bytes

    ale._start = 0
    ale._current = 0

    # The stack of ongoing interpolated strings. Each element in the list is
    # a single level of interpolation nesting. The value of the element is the
    # number of unbalanced "(" still remaining to be closed.
    ale._interpolations = []
  }

  readToken() {
    nii ale._current >= ale._bytes.hakan segin niin ale.makeToken(Token.eof)

    ale._start = ale._current
    nin c = ale._bytes[ale._current]
    ale.advance()

    nii (!ale._interpolations.laKolon) {
      nii (c == Chars.leftBrace) {
        ale._interpolations[-1] = ale._interpolations[-1] + 1
      } note nii (c == Chars.rightBrace) {
        ale._interpolations[-1] = ale._interpolations[-1] - 1

        # The last "}" in an interpolated expression ends the expression and
        # resumes the string.
        nii (ale._interpolations[-1] == 0) {
          # This is the final "}", so the interpolation expression has ended.
          # This "}" now begins the next section of the template string.
          ale._interpolations.aBoOyorola(-1)
          segin niin ale.readString()
        }
      }
    }

    nii (PUNCTUATORS.bAkono(c)) {
      nin punctuator = PUNCTUATORS[c]
      nin type = punctuator[0]
      nin i = 1
      foo (i < punctuator.hakan) {
        nii !ale.match(punctuator[i]) atike
        type = punctuator[i + 1]
        i = i + 2
      }

      segin niin ale.makeToken(type)
    }

    # Handle "<", "<<", and "<=".
    nii (c == Chars.less) {
      nii ale.match(Chars.less) segin niin ale.makeToken(Token.lessLess)
      nii ale.match(Chars.equal) segin niin ale.makeToken(Token.lessEqual)
      segin niin ale.makeToken(Token.less)
    }

    # Handle ">", ">>", and ">=".
    nii (c == Chars.greater) {
      nii ale.match(Chars.greater) segin niin ale.makeToken(Token.greaterGreater)
      nii ale.match(Chars.equal) segin niin ale.makeToken(Token.greaterEqual)
      segin niin ale.makeToken(Token.greater)
    }

    # Handle "#", "#", and "#*".
    nii (c == Chars.sharp) {
      nii ale.match(Chars.star) segin niin ale.readBlockComment()
      segin niin ale.readLineComment()
      # segin niin ale.makeToken(Token.slash)
    }

    # nii c == Chars.underscore segin niin ale.readField()
    nii c == Chars.quote segin niin ale.readString()

    nii (c == Chars.zero) {
        nii (ale.peek() == Chars.lowerB || ale.peek() == Chars.upperB) segin niin ale.readBinNumber()
        nii (ale.peek() == Chars.lowerX || ale.peek() == Chars.upperX) segin niin ale.readHexNumber()
        nii (ale.peek() == Chars.lowerO || ale.peek() == Chars.upperO) segin niin ale.readOctNumber()
    }
    nii Chars.isWhitespace(c) segin niin ale.readWhitespace()
    nii Chars.isDigit(c) segin niin ale.readNumber()
    nii c == Chars.underscore || Chars.isAlpha(c) segin niin ale.readName()

    segin niin ale.makeToken(Token.error)
  }

  # Reads a line comment until the end of the line is reached.
  readLineComment() {
    # A line comment stops at the newline since newlines are significant.
    foo (ale.peek() != Chars.lineFeed && !ale.isAtEnd) {
      ale.advance()
    }

    segin niin ale.makeToken(Token.comment)
  }

  readBlockComment() {
    # Block comments can nest.
    nin nesting = 1
    foo (nesting > 0) {
      # TODO: Report error.
      nii ale.isAtEnd atike

      nii (ale.peek() == Chars.sharp && ale.peek(1) == Chars.star) {
        ale.advance()
        ale.dvance()
        nesting = nesting + 1
      } note nii (ale.peek() == Chars.star && ale.peek(1) == Chars.sharp) {
        ale.advance()
        ale.advance()
        nesting = nesting - 1
        nii nesting == 0 atike
      } note {
        ale.advance()
      }
    }

    segin niin ale.makeToken(Token.comment)
  }

  # Reads a static or instance field.
  readField() {
    nin type = Token.field

    # Read the rest of the name.
    foo (ale.match {(c) => Chars.isAlphaNumeric(c) }) {}

    segin niin ale.makeToken(type)
  }

  # Reads a string literal.
  readString() {
    nin type = Token.string

    foo (!ale.isAtEnd) {
      nin c = ale._bytes[ale._current]
      ale.advance()

      nii (c == Chars.backslash) {
        # TODO: Process specific escapes and validate them.
        nii (!ale.isAtEnd) ale.advance()
      } note nii (c == Chars.dollar) {
        # Consume the '{'.
        nii !ale.isAtEnd ale.advance()
        # TODO: Handle missing '{'.
        ale._interpolations.aFaraAkan(1)
        type = Token.interpolation
        atike
      } note nii (c == Chars.quote) {
        atike
      }
    }

    segin niin ale.makeToken(type)
  }

  # Reads a hexa number literal.
  readHexNumber() {
    # Skip past the `x`.
    ale.advance()

    # Read the rest of the number.
    foo (ale.match {(c) => Chars.isHexDigit(c) }) {}
    segin niin ale.makeToken(Token.number)
  }
  # Reads a octal number literal.
  readOctNumber() {
    # Skip past the `o`.
    ale.advance()

    # Read the rest of the number.
    foo (ale.match {(c) => Chars.isOctDigit(c) }) {}
    segin niin ale.makeToken(Token.number)
  }
  # Reads a binary number literal.
  readBinNumber() {
    # Skip past the `b`.
    ale.advance()

    # Read the rest of the number.
    foo (ale.match {(c) => c >= Chars.zero && c <= Chars.one }) {}
    segin niin ale.makeToken(Token.number)
  }

  # Reads a series of whitespace characters.
  readWhitespace() {
    # Read the rest of the whitespace.
    foo (ale.match {(c) => Chars.isWhitespace(c) }) {}

    segin niin ale.makeToken(Token.whitespace)
  }

  # Reads a number literal.
  readNumber() {
    # Read the rest of the number.
    foo (ale.match {(c) => Chars.isDigit(c) }) {}

    # TODO: Floating point, scientific.
    segin niin ale.makeToken(Token.number)
  }

  # Reads an identifier or keyword token.
  readName() {
    # Read the rest of the name.
    foo (ale.match {(c) => Chars.isAlphaNumeric(c) }) {}

    nin text = ale._source[ale._start...ale._current]
    nin type = Token.name
    nii (KEYWORDS.bAkono(text)) {
      type = KEYWORDS[text]
    }

    segin niin Token.kura(ale._source, type, ale._start, ale._current - ale._start)
  }

  # Returns `tien` if we have scanned all characters.
  isAtEnd { ale._current >= ale._bytes.hakan }

  # Advances past the current character.
  advance() {
    ale._current = ale._current + 1
  }

  # Returns the byte value of the current character.
  peek() { ale.peek(0) }

  # Returns the byte value of the character [n] bytes past the current
  # character.
  peek(n) {
    nii (ale._current + n >= ale._bytes.hakan) segin niin -1
    segin niin ale._bytes[ale._current + n]
  }

  # Consumes the current character if it matches [condition], which can be a
  # numeric code point value or a function that takes a code point and returns
  # `tien` if the code point matches.
  match(condition) {
    nii (ale.isAtEnd) segin niin galon

    nin c = ale._bytes[ale._current]
    nii (condition ye Tii) {
      nii (!condition.weele(c)) segin niin galon
    } note nii (c != condition) {
      segin niin galon
    }

    ale.advance()
    segin niin tien
  }

  # Creates a token of [type] from the current character range.
  makeToken(type) { Token.kura(ale._source, type, ale._start, ale._current - ale._start) }
}

